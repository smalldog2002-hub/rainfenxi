import streamlit as st
import pandas as pd
import numpy as np
import altair as alt

# --- å®‰å…¨å¯¼å…¥ AI åº“ ---
try:
    import google.generativeai as genai
    HAS_GENAI = True
except ImportError:
    HAS_GENAI = False

# âœ… é˜²æ­¢æœªå®šä¹‰
uploaded_file = None
yearly_sums = None  # ç»™ AI ç”¨ï¼Œé¿å…æœªå®šä¹‰

# âœ… é€šç”¨å®‰å…¨é™¤æ³•ï¼ˆé¿å… ZeroDivisionErrorï¼‰
def safe_div(num, den, default=np.nan):
    try:
        if den is None or den == 0:
            return default
        return num / den
    except Exception:
        return default

def fmt_num(x, fmt=".0f", na="â€”"):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return na
    try:
        return format(float(x), fmt)
    except Exception:
        return na

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="æ°´æ–‡æ°”å€™æ™ºèƒ½åˆ†æç³»ç»Ÿ", page_icon="ğŸŒŠ", layout="wide")

# --- åˆå§‹åŒ– Session ---
if 'ai_report' not in st.session_state: st.session_state.ai_report = ""
if 'chat_history' not in st.session_state: st.session_state.chat_history = []

# --- ä¾§è¾¹æ ï¼šè®¾ç½® ---
with st.sidebar:
    st.title("âš™ï¸ è®¾ç½®")

    # --- Gemini Key ---
    if HAS_GENAI:
        try:
            secrets_key = st.secrets.get("GEMINI_API_KEY", "")
        except FileNotFoundError:
            secrets_key = ""

        if secrets_key:
            st.success("âœ… API Key å·²åŠ è½½")
            if st.toggle("ä¸´æ—¶ä½¿ç”¨å…¶ä»– Key"):
                api_key = st.text_input("æ‰‹åŠ¨è¾“å…¥æ–° Key", type="password")
            else:
                api_key = secrets_key
        else:
            api_key = st.text_input("Gemini API Key", type="password", help="è¾“å…¥ Key ä»¥å¼€å¯ AI åŠŸèƒ½")
    else:
        api_key = ""

    st.divider()
    data_source = st.radio("æ•°æ®æ¥æº", ["ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® (æ¼”ç¤º)", "ä¸Šä¼  CSV æ–‡ä»¶"])

    if data_source == "ä¸Šä¼  CSV æ–‡ä»¶":
        uploaded_file = st.file_uploader("è¯·ä¸Šä¼ å« 'date' å’Œ 'rainfall' åˆ—çš„æ–‡ä»¶", type="csv")

    st.divider()

    # âœ… æš´é›¨é˜ˆå€¼è¾“å…¥æ¡†ï¼ˆå…¨ç³»ç»Ÿç»Ÿä¸€ï¼‰
    storm_threshold = st.number_input(
        "æš´é›¨é˜ˆå€¼ (mm/æ—¥)",
        min_value=1.0,
        max_value=500.0,
        value=50.0,
        step=5.0,
        help="ç”¨äºæš´é›¨å¤©æ•°/æ¦‚ç‡ç»Ÿè®¡ã€‚å¸¸ç”¨ï¼š30/50/80 mmã€‚"
    )

    # âœ… æš´é›¨é¢‘ç‡å£å¾„åˆ‡æ¢
    storm_metric_mode = st.radio(
        "æš´é›¨é¢‘ç‡å£å¾„",
        ["æ¬¡/å¹´ï¼ˆæš´é›¨å¤©æ•°/å¹´ä»½æ•°ï¼‰", "æš´é›¨æ¦‚ç‡ï¼ˆæš´é›¨å¤©æ•°/æ€»å¤©æ•°ï¼‰"],
        index=1,
        help="æ¬¡/å¹´è¡¡é‡æ¯å¹´æš´é›¨å¤©æ•°å¼ºåº¦ï¼›æš´é›¨æ¦‚ç‡æ›´æ¥è¿‘é¢‘ç‡ï¼ˆæš´é›¨æ—¥å æ¯”ï¼‰ã€‚"
    )

# --- 1. æ•°æ®åŠ è½½ä¸å¤„ç† ---
@st.cache_data
def get_data(source, uploaded_file):
    if source == "ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® (æ¼”ç¤º)":
        dates = pd.date_range(start="2004-01-01", end="2023-12-31", freq='D')
        np.random.seed(42)
        rainfall = np.random.exponential(scale=3, size=len(dates))
        seasonality = np.array([1 + 2.5 * np.sin(np.pi * (m-2) / 6) if 4 < m < 10 else 0.2 for m in dates.month])
        mask = np.random.rand(len(dates)) > 0.75
        yearly_factor = np.ones(len(dates))
        for i, d in enumerate(dates):
            if d.year == 2010: yearly_factor[i] = 1.5
            if d.year == 2015: yearly_factor[i] = 0.6
        final_rain = rainfall * seasonality * mask * 5 * yearly_factor
        df = pd.DataFrame({"date": dates, "rainfall": final_rain})
        df['rainfall'] = df['rainfall'].clip(lower=0).round(1)
    else:
        if uploaded_file:
            try:
                df = pd.read_csv(uploaded_file)

                # âœ… åˆ—æ£€æŸ¥
                if 'date' not in df.columns or 'rainfall' not in df.columns:
                    st.error("CSV å¿…é¡»åŒ…å« 'date' å’Œ 'rainfall' ä¸¤åˆ—ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰")
                    return None

                df['date'] = pd.to_datetime(df['date'], errors="coerce")
                df['rainfall'] = pd.to_numeric(df['rainfall'], errors="coerce").fillna(0.0)

                # âœ… å»æ‰æ— æ³•è§£ææ—¥æœŸçš„è¡Œ
                df = df.dropna(subset=['date']).copy()
            except Exception as e:
                st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
                return None
        else:
            return None

    if df is None or df.empty:
        return None

    df['year'] = df['date'].dt.year
    df['month'] = df['date'].dt.month
    df['day'] = df['date'].dt.day
    return df

df = get_data(data_source, uploaded_file if data_source == "ä¸Šä¼  CSV æ–‡ä»¶" else None)

# --- ä¸»ç•Œé¢ ---
st.title("ğŸŒŠ æ°´æ–‡æ°”å€™æ™ºèƒ½åˆ†æç³»ç»Ÿ")

if df is None:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©æ•°æ®æ¥æºï¼Œæˆ–æŸ¥çœ‹ã€Œæ•°æ®æŒ‡å—ã€ä¸‹è½½æ ·è¡¨ã€‚")
else:
    # --- è®¡ç®—åŸºç¡€æŒ‡æ ‡ ---
    yearly_sums = df.groupby('year', as_index=False)['rainfall'].sum()
    avg_annual = yearly_sums['rainfall'].mean()
    max_day = df['rainfall'].max()

    # é¡¶éƒ¨æŒ‡æ ‡æ ï¼ˆå…¨å±€æ¦‚è§ˆï¼‰
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("å¹´å‡é™é›¨é‡", f"{fmt_num(avg_annual, '.0f')} mm")
    c2.metric("å†å²æå€¼ (å•æ—¥)", f"{fmt_num(max_day, '.1f')} mm")
    c3.metric("æ€»é™é›¨å¤©æ•°", f"{int((df['rainfall'] > 0.1).sum())} å¤©")
    c4.metric("è®°å½•å¹´ä»½", f"{df['year'].nunique()} å¹´")

st.markdown("---")

# === åˆ†é¡µåŠŸèƒ½åŒº ===
tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(
    ["ğŸ“Š åŸºç¡€æ¦‚è§ˆ", "ğŸ“… æ—¥å†çƒ­åŠ›å›¾", "âš–ï¸ æ—¶æ®µå¯¹æ¯”", "ğŸ“‰ æ·±åº¦æ°´æ–‡", "ğŸŒŠ æ´ªæ°´æ¼”è¿›æ¨¡æ‹Ÿ", "ğŸ’¬ AI åŠ©æ‰‹", "ğŸ“š æ•°æ®æŒ‡å—"]
)

# åªæœ‰å½“ df å­˜åœ¨æ—¶æ‰æ¸²æŸ“å‰6ä¸ª Tab
if df is not None:

    # --- Tab 1: åŸºç¡€æ¦‚è§ˆ ---
    with tab1:
        # âœ… æ–°å¢ï¼šé˜ˆå€¼æš´é›¨ç»Ÿè®¡æ¥å…¥ Tab1 æ¦‚è§ˆæŒ‡æ ‡
        st.subheader("æ¦‚è§ˆæŒ‡æ ‡ï¼ˆå«é˜ˆå€¼æš´é›¨ç»Ÿè®¡ï¼‰")

        storm_by_year = df.assign(is_storm=df["rainfall"] >= storm_threshold).groupby("year").agg(
            storm_days=("is_storm", "sum"),
            total_days=("is_storm", "size"),
        ).reset_index()
        storm_by_year["storm_prob"] = safe_div(storm_by_year["storm_days"], storm_by_year["total_days"], default=0.0)

        avg_storm_days = storm_by_year["storm_days"].mean() if len(storm_by_year) else np.nan
        avg_storm_prob = storm_by_year["storm_prob"].mean() if len(storm_by_year) else np.nan

        m1, m2, m3, m4, m5, m6 = st.columns(6)
        m1.metric("å¹´å‡é™é›¨é‡", f"{fmt_num(avg_annual, '.0f')} mm")
        m2.metric("å†å²æå€¼(å•æ—¥)", f"{fmt_num(max_day, '.1f')} mm")
        m3.metric("è®°å½•å¹´ä»½", f"{df['year'].nunique()} å¹´")
        m4.metric("æ€»é™é›¨å¤©æ•°", f"{int((df['rainfall'] > 0.1).sum())} å¤©")
        m5.metric(f"å¤šå¹´å¹³å‡æš´é›¨å¤©æ•° (â‰¥{storm_threshold:g}mm)", f"{fmt_num(avg_storm_days, '.1f')} å¤©/å¹´")
        m6.metric(f"å¤šå¹´å¹³å‡æš´é›¨æ¦‚ç‡ (â‰¥{storm_threshold:g}mm)", f"{fmt_num(avg_storm_prob, '.1%')}")

        st.markdown("")

        col_charts_1, col_charts_2 = st.columns([2, 1])

        with col_charts_1:
            st.subheader("å†å¹´é™é›¨æ€»é‡ & è¶‹åŠ¿")
            yearly_sums_local = df.groupby('year')['rainfall'].sum().reset_index()
            yearly_sums_local['MA_5'] = yearly_sums_local['rainfall'].rolling(window=5).mean()

            bar = alt.Chart(yearly_sums_local).mark_bar(color='#3b82f6', opacity=0.8).encode(
                x=alt.X('year:O', title='å¹´ä»½'),
                y=alt.Y('rainfall:Q', title='æ€»é™é›¨é‡ (mm)'),
                tooltip=['year', 'rainfall']
            )
            line = alt.Chart(yearly_sums_local).mark_line(color='#f59e0b', strokeWidth=3).encode(
                x='year:O', y='MA_5:Q',
                tooltip=[alt.Tooltip('MA_5', title='5å¹´å¹³å‡çº¿', format='.0f')]
            )
            st.altair_chart((bar + line).interactive(), use_container_width=True)

        with col_charts_2:
            st.subheader("æœˆåº¦æ¨¡å¼")
            monthly_avg = df.groupby('month')['rainfall'].mean().reset_index()
            line_chart = alt.Chart(monthly_avg).mark_area(
                color=alt.Gradient(
                    gradient='linear',
                    stops=[
                        alt.GradientStop(color='#10b981', offset=0),
                        alt.GradientStop(color='white', offset=1)
                    ],
                    x1=1, x2=1, y1=1, y2=0
                )
            ).encode(
                x=alt.X('month:O', title='æœˆä»½'),
                y=alt.Y('rainfall:Q', title='æ—¥å‡é™é›¨ (mm)'),
                tooltip=['month', 'rainfall']
            ).properties(height=350)
            st.altair_chart(line_chart, use_container_width=True)

    # --- Tab 2: æ—¥å†çƒ­åŠ›å›¾ ---
    with tab2:
        st.subheader("ğŸ—“ï¸ æ¯æ—¥é™é›¨å¾®è§‚è§†å›¾")
        selected_year = st.selectbox("é€‰æ‹©å¹´ä»½æŸ¥çœ‹è¯¦æƒ…:", sorted(df['year'].unique(), reverse=True))
        year_data = df[df['year'] == selected_year]
        heatmap = alt.Chart(year_data).mark_rect().encode(
            x=alt.X('day:O', title='æ—¥æœŸ'),
            y=alt.Y('month:O', title='æœˆä»½'),
            color=alt.Color('rainfall:Q', scale=alt.Scale(scheme='blues'), title='é™é›¨é‡(mm)'),
            tooltip=['date', 'rainfall']
        ).properties(width='container', height=400)
        st.altair_chart(heatmap, use_container_width=True)

    # --- Tab 3: æ—¶æ®µå¯¹æ¯” ---
    with tab3:
        st.subheader("âš–ï¸ æ°”å€™å˜åŒ–æ£€æµ‹ (å‰åŠæ®µ vs ååŠæ®µ)")

        years = sorted(df['year'].unique())
        if len(years) < 2:
            st.info("å¹´ä»½å¤ªå°‘ï¼Œæ— æ³•è¿›è¡Œæ—¶æ®µå¯¹æ¯”ã€‚è¯·è‡³å°‘æä¾› 2 å¹´æ•°æ®ã€‚")
        else:
            mid_point = len(years) // 2
            period_1 = years[:mid_point]
            period_2 = years[mid_point:]

            if len(period_1) == 0 or len(period_2) == 0:
                st.warning("åˆ†æ®µåå‡ºç°ç©ºæ—¶æ®µï¼Œæ— æ³•å¯¹æ¯”ã€‚å»ºè®®è‡³å°‘ 4 å¹´æ•°æ®æ•ˆæœæ›´å¥½ã€‚")
            else:
                df_p1 = df[df['year'].isin(period_1)].copy()
                df_p2 = df[df['year'].isin(period_2)].copy()

                avg_p1 = df_p1.groupby('year')['rainfall'].sum().mean()
                avg_p2 = df_p2.groupby('year')['rainfall'].sum().mean()

                # âœ… æš´é›¨ç»Ÿè®¡ç»Ÿä¸€ä½¿ç”¨ storm_threshold
                num1 = (df_p1["rainfall"] >= storm_threshold).sum()
                num2 = (df_p2["rainfall"] >= storm_threshold).sum()

                if storm_metric_mode == "æ¬¡/å¹´ï¼ˆæš´é›¨å¤©æ•°/å¹´ä»½æ•°ï¼‰":
                    den1 = len(period_1)   # å¹´ä»½æ•°
                    den2 = len(period_2)
                    storm_p1 = safe_div(num1, den1, default=0.0)
                    storm_p2 = safe_div(num2, den2, default=0.0)
                    storm_label = f"æš´é›¨é¢‘ç‡å˜åŒ– (â‰¥{storm_threshold:g}mm)"
                    storm_fmt = ".1f"
                    storm_suffix = " æ¬¡/å¹´"
                else:
                    den1 = len(df_p1)      # æ€»å¤©æ•°
                    den2 = len(df_p2)
                    storm_p1 = safe_div(num1, den1, default=0.0)
                    storm_p2 = safe_div(num2, den2, default=0.0)
                    storm_label = f"æš´é›¨æ¦‚ç‡å˜åŒ– (â‰¥{storm_threshold:g}mm)"
                    storm_fmt = ".1%"
                    storm_suffix = ""

                col_a, col_b, col_c = st.columns(3)
                col_a.metric("æ—©æœŸå¹³å‡é™é›¨", f"{fmt_num(avg_p1, '.0f')} mm", f"{period_1[0]}-{period_1[-1]}")
                col_b.metric("è¿‘æœŸå¹³å‡é™é›¨", f"{fmt_num(avg_p2, '.0f')} mm", f"{fmt_num((avg_p2 - avg_p1), '.0f')} mm", delta_color="inverse")
                col_c.metric(
                    storm_label,
                    f"{format(storm_p2, storm_fmt)}{storm_suffix}",
                    f"{format(storm_p2 - storm_p1, storm_fmt)}",
                    delta_color="inverse"
                )

    # --- Tab 4: æ·±åº¦æ°´æ–‡åˆ†æ ---
    with tab4:
        c_hyd_1, c_hyd_2 = st.columns(2)

        with c_hyd_1:
            st.subheader("â›ˆï¸ æ—±æ¶å¼‚å¸¸ç›‘æµ‹ (è·å¹³)")

            yearly_sums_local = df.groupby('year')['rainfall'].sum().reset_index()
            avg_annual_local = yearly_sums_local['rainfall'].mean()

            # âœ… ä¿®å¤ï¼šavg_annual å¯èƒ½ä¸º 0
            if avg_annual_local == 0 or np.isnan(avg_annual_local):
                st.warning("å¹´å‡é™é›¨é‡ä¸º 0 æˆ–æ— æ•ˆï¼Œæ— æ³•è®¡ç®—è·å¹³æŒ‡æ•°ã€‚")
                yearly_sums_local['anomaly_pct'] = 0.0
            else:
                yearly_sums_local['anomaly_pct'] = (yearly_sums_local['rainfall'] - avg_annual_local) / avg_annual_local

            anomaly_chart = alt.Chart(yearly_sums_local).mark_bar().encode(
                x=alt.X('year:O', title='å¹´ä»½'),
                y=alt.Y('anomaly_pct:Q', title='è·å¹³æŒ‡æ•°', axis=alt.Axis(format='%')),
                color=alt.condition(alt.datum.anomaly_pct > 0, alt.value("#3b82f6"), alt.value("#ef4444")),
                tooltip=[alt.Tooltip('year'), alt.Tooltip('anomaly_pct', format='.1%')]
            ).properties(height=300)
            st.altair_chart(anomaly_chart, use_container_width=True)

        with c_hyd_2:
            st.subheader("ğŸŒŠ æš´é›¨é‡ç°æœŸæ¨ç®—ï¼ˆå¹´æœ€å¤§æ—¥é›¨é‡ï¼‰")
            annual_max = df.groupby('year')['rainfall'].max().sort_values(ascending=False).reset_index()
            n = len(annual_max)

            if n < 2:
                st.info("å¹´ä»½å¤ªå°‘ï¼Œæ— æ³•æ¨ç®—é‡ç°æœŸã€‚è¯·è‡³å°‘æä¾› 2 å¹´æ•°æ®ã€‚")
            else:
                annual_max['rank'] = range(1, n + 1)
                annual_max['prob'] = annual_max['rank'] / (n + 1)
                annual_max['return_period'] = 1 / annual_max['prob']

                rp_chart = alt.Chart(annual_max).mark_circle(size=60, color='#f59e0b').encode(
                    x=alt.X('return_period:Q', title='é‡ç°æœŸ (å¹´)', scale=alt.Scale(type='log')),
                    y=alt.Y('rainfall:Q', title='æ—¥æœ€å¤§é™é›¨é‡ (mm)'),
                    tooltip=['year', 'rainfall', alt.Tooltip('return_period', format='.1f')]
                ).properties(height=300)

                trend = rp_chart.transform_regression('return_period', 'rainfall', method='log').mark_line(color='gray')
                st.altair_chart(rp_chart + trend, use_container_width=True)

            # âœ… æ–°å¢ï¼šé˜ˆå€¼æš´é›¨ç»Ÿè®¡ï¼ˆä¸ Tab3 åŒä¸€é˜ˆå€¼ï¼‰
            st.markdown(f"---\n**é˜ˆå€¼æš´é›¨ç»Ÿè®¡ï¼ˆâ‰¥{storm_threshold:g} mm/æ—¥ï¼‰**")

            storm_by_year = df.assign(is_storm=df["rainfall"] >= storm_threshold).groupby("year").agg(
                storm_days=("is_storm", "sum"),
                total_days=("is_storm", "size"),
            ).reset_index()

            storm_by_year["storm_prob"] = storm_by_year["storm_days"] / storm_by_year["total_days"]

            avg_storm_days = storm_by_year["storm_days"].mean()
            avg_storm_prob = storm_by_year["storm_prob"].mean()

            mm1, mm2 = st.columns(2)
            mm1.metric("å¤šå¹´å¹³å‡æš´é›¨å¤©æ•°", f"{avg_storm_days:.1f} å¤©/å¹´")
            mm2.metric("å¤šå¹´å¹³å‡æš´é›¨æ¦‚ç‡", f"{avg_storm_prob:.1%}")

            storm_trend = alt.Chart(storm_by_year).mark_line(point=True).encode(
                x=alt.X("year:O", title="å¹´ä»½"),
                y=alt.Y("storm_days:Q", title=f"æš´é›¨å¤©æ•° (â‰¥{storm_threshold:g}mm)"),
                tooltip=["year", "storm_days", alt.Tooltip("storm_prob", format=".1%")]
            ).properties(height=220)
            st.altair_chart(storm_trend, use_container_width=True)

    # --- Tab 5: æ´ªæ°´æ¼”è¿›æ¨¡æ‹Ÿ ---
    with tab5:
        st.subheader("ğŸŒŠ æ²³é“æ´ªæ°´æ¼”è¿›æ¨¡æ‹Ÿ (é©¬æ–¯é‡‘æ ¹æ³•)")
        st.caption("åŸºäºä¸Šæ¸¸æµé‡æ•°æ®ï¼Œæ¨¡æ‹Ÿæ´ªæ°´åœ¨æ²³é“ä¸­çš„ä¼ æ’­ã€æ»åä¸å‰Šå³°è¿‡ç¨‹ã€‚")

        col_sim_1, col_sim_2 = st.columns([1, 2])

        with col_sim_1:
            st.markdown("#### 1. è®¾å®šæ´ªæ°´åœºæ™¯")
            peak_flow = st.slider("ä¸Šæ¸¸æ´ªå³°æµé‡ (mÂ³/s)", 100, 5000, 1000)
            base_flow = st.slider("åŸºç¡€æµé‡ (mÂ³/s)", 10, 500, 50)
            flood_duration = st.slider("æ´ªæ°´æŒç»­æ—¶é—´ (å°æ—¶)", 10, 100, 24)

            st.markdown("#### 2. è®¾å®šæ²³é“å‚æ•°")
            K = st.slider("ä¼ æ’­æ—¶é—´ K (å°æ—¶)", 1.0, 20.0, 5.0)
            X = st.slider("è°ƒè“„ç³»æ•° X", 0.0, 0.5, 0.2)

        with col_sim_2:
            time_steps = np.arange(0, 100, 1)
            peak_time = 20
            inflow = base_flow + (peak_flow - base_flow) * np.exp(-0.5 * ((time_steps - peak_time) / (flood_duration / 4))**2)

            dt = 1.0
            denom = K * (1 - X) + 0.5 * dt

            if denom == 0:
                st.error("å‚æ•°ç»„åˆå¯¼è‡´ denom=0ï¼ˆæ— æ³•è®¡ç®—é©¬æ–¯é‡‘æ ¹ç³»æ•°ï¼‰ï¼Œè¯·è°ƒæ•´ K/Xã€‚")
            else:
                C0 = (-K * X + 0.5 * dt) / denom
                C1 = (K * X + 0.5 * dt) / denom
                C2 = (K * (1 - X) - 0.5 * dt) / denom

                outflow = np.zeros(len(time_steps))
                outflow[0] = inflow[0]

                for t in range(1, len(time_steps)):
                    outflow[t] = C0 * inflow[t] + C1 * inflow[t-1] + C2 * outflow[t-1]
                    if outflow[t] < base_flow:
                        outflow[t] = base_flow

                sim_df = pd.DataFrame({'Time': time_steps, 'Inflow': inflow, 'Outflow': outflow}).melt(
                    'Time', var_name='Type', value_name='Flow'
                )

                hydrograph = alt.Chart(sim_df).mark_line(strokeWidth=3).encode(
                    x='Time', y='Flow',
                    color=alt.Color('Type', scale=alt.Scale(range=['#3b82f6', '#f59e0b'])),
                    tooltip=['Time', 'Type', 'Flow']
                ).properties(height=400, title="æ´ªæ°´æ¼”è¿›è¿‡ç¨‹çº¿")
                st.altair_chart(hydrograph, use_container_width=True)

    # --- Tab 6: AI æ•°æ®å¯¹è¯ ---
    with tab6:
        st.subheader("ğŸ’¬ AI æ°´æ–‡æ•°æ®åŠ©æ‰‹")

        for msg in st.session_state.chat_history:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

        if prompt := st.chat_input("å‘æ•°æ®æé—®..."):
            if not api_key:
                st.error("è¯·å…ˆé…ç½® API Key")
            else:
                st.session_state.chat_history.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                with st.chat_message("assistant"):
                    with st.spinner("AI æ€è€ƒä¸­..."):
                        try:
                            yearly_txt = yearly_sums.to_string(index=False) if yearly_sums is not None else ""
                            data_context = f"å†å¹´é™é›¨(Year:mm):\n{yearly_txt}"
                            full_prompt = (
                                "ä½ æ˜¯ä¸€ä¸ªæ°´æ–‡æ•°æ®åŠ©æ‰‹ã€‚è¯·åŸºäºç»™å®šæ•°æ®ï¼Œç”¨ç®€æ´ã€å¯æ ¸éªŒçš„æ–¹å¼å›ç­”ã€‚\n"
                                f"{data_context}\n"
                                f"æš´é›¨é˜ˆå€¼ï¼šâ‰¥{storm_threshold:g} mm/æ—¥\n"
                                f"é—®é¢˜: {prompt}"
                            )
                            genai.configure(api_key=api_key)
                            model = genai.GenerativeModel('gemini-2.5-flash-preview-09-2025')
                            res = model.generate_content(full_prompt)
                            st.markdown(res.text)
                            st.session_state.chat_history.append({"role": "assistant", "content": res.text})
                        except Exception as e:
                            st.error(f"Error: {e}")

# --- Tab 7: æ•°æ®æŒ‡å— (æ— è®ºæ˜¯å¦æœ‰æ•°æ®éƒ½æ˜¾ç¤º) ---
with tab7:
    st.subheader("ğŸ“š æ•°æ®å‡†å¤‡ä¸ä¸Šä¼ æŒ‡å—")

    st.markdown("""
    ### 1. æ–‡ä»¶æ ¼å¼æ ‡å‡†
    * **æ–‡ä»¶ç±»å‹**ï¼š`.csv` (é€—å·åˆ†éš”å€¼æ–‡ä»¶)
    * **ç¼–ç æ ¼å¼**ï¼šæ¨è `UTF-8`

    ### 2. æ•°æ®åˆ—è¦æ±‚
    ä½ çš„è¡¨æ ¼**å¿…é¡»**åŒ…å«ä»¥ä¸‹ä¸¤åˆ—è¡¨å¤´ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰ï¼š

    | åˆ—å (Header) | æ•°æ®ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
    | :--- | :--- | :--- | :--- |
    | **date** | æ—¥æœŸ | æ ¼å¼ `YYYY-MM-DD` | `2004-01-01` |
    | **rainfall** | æ•°å­— | é™é›¨é‡ (mm) | `25.4` |

    ### 3. æ•°æ®è´¨é‡å»ºè®®
    * **ç¼ºå¤±å€¼**ï¼šæŸå¤©æ²¡ä¸‹é›¨è¯·å¡« `0`ï¼Œä¸è¦ç•™ç©ºã€‚
    * **æ—¶é—´è·¨åº¦**ï¼šå»ºè®®è‡³å°‘ 2 å¹´çš„æ•°æ®ï¼ˆå¯¹æ¯”åˆ†ææ›´ç¨³å®šï¼‰ï¼Œæ´ªæ°´æ¨¡æ‹Ÿå»ºè®® 10 å¹´ä»¥ä¸Šã€‚
    """)

    st.divider()

    st.subheader("ğŸ“¥ ä¸‹è½½æ ‡å‡†æ ·è¡¨")

    sample_data = pd.DataFrame({
        "date": pd.date_range(start="2023-01-01", periods=10, freq="D"),
        "rainfall": [0, 5.2, 12.8, 0, 0, 45.5, 2.1, 0, 0, 8.4]
    })

    csv = sample_data.to_csv(index=False).encode('utf-8')

    st.download_button(
        label="ç‚¹å‡»ä¸‹è½½ CSV æ ·è¡¨ (template.csv)",
        data=csv,
        file_name="rainfall_template.csv",
        mime="text/csv",
    )
